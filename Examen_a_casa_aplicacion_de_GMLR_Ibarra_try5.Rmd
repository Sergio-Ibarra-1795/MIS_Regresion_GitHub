---
title: "Examen_a_casa_aplicacion_de_GMLR_Ibarra_try5"
author: "SIR"
date: "2023-11-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### UNAM Posgrado en Ingeniería 
### Dr. Wulfrano Gomez Gallardo
### Alumno: Ibarra Ramírez Sergio 
<br>

### Ejemplo de aplicación de modelos Lineales Generalizados (GLR Ó MCG) en el pronóstico de sueldos

<br>


#### El modelo General Lineal Simple o Modelo de Mínimos Cuadrados Ordinarios 

Consideremos al modelo de regresión lineal simple o modelo de Mínimos Cuadrados Ordinarios (OMS ó MCO) como: 

$$\begin{align}
\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}
\end{align}$$


Donde: <br>
Y: Vector de valores estimados <br>
X: Matriz ampliada de valores de las variables independientes xi <br>
$\beta$: Vector de estimadores de maxima verosimilitud calculado con el modelo MCO 


El cual asume: 

$$Y |X \sim \operatorname{N}(\mu(X), \sigma^2I)$$ 

Donde: <br>
Y: Vector de valores estimados <br>
X: Matriz ampliada de valores de las variables independientes xi <br>
$\mu(X)$ es la media de la distribución normal <br>
$\sigma^2I$ es la varianza  de la distribución normal,I es la matriz identidad.

Y  por lo tanto: 

$$E(Y |X) = \mu(X) = \mathbf{X}^\top\boldsymbol{\beta}$$


##### Coeficientes ${\beta}_{OLS}$ del Modelo MCO

Y cuyos coeficientes son calculados con base en los datos de la muestra de la siguiente manera:

$$\widehat{\boldsymbol{\beta}}_{OLS} = \left( \mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{X}^\top \mathbf{Y}$$


<br>

#### La prueba estadística F(Fisher) para evaluación de valor general constante para todos los elementos del vecotr ${\beta}$

Donde la H0: El vector ${\beta}$ es igual a un valor determinado para todos sus elementos, por ejemplo ${\beta}=r$ donde r=0

$$\begin{cases}
H_0&: \boldsymbol{\beta} = \boldsymbol{r}\\
H_1&: \boldsymbol{\beta} \neq \boldsymbol{r}
\end{cases}$$


Donde se asume que ambos errores:<br>
a) Error explicado por el modelo con k grados de libertad <br>
b) Error no explicado por el modelo (error estocástico) con n-k grados de libertad siguen ambos una distribución t de student para una determinada muestra y por lo tanto, el cociente de ambas cantidades pueden intepretarse como un estadístico F de fisher con K,N-K grados de libertad: 



$$F = \dfrac{ \left(\widehat{\boldsymbol{\beta}}_{OLS}- \beta^* \right)^\top \left[\left( \mathbf{X}^\top \mathbf{X}  \right)\right]^{-1} \left( \widehat{\boldsymbol{\beta}}_{OLS}- \beta^* \right)}{\widehat{\epsilon}^2}  \sim F_{(K, N - K)} $$


La prueba F de significación general compara un modelo sin predictores con el modelo especificado. Un modelo de regresión que no contiene predictores también se conoce como modelo de solo intersección, donde todos los valores ajustados son iguales a la media de la variable de respuesta. Por tanto, si el valor p de la prueba F general es menor que el nivel de significancia α, el modelo especificado predice la variable de respuesta mejor que la media de la respuesta.



#### Las pruebas estadística T(student) para evaluación de valor individual de cada  elemento del vecotr ${\beta}$

Donde la H0: El i-esimo elemento del vector ${\beta}$ es igual a un valor determinado , por ejemplo ${\beta_{i}}=r$ donde puede ser cero r=0 ç


$$\begin{cases}
H_0&: \boldsymbol{\beta_{j}} = \boldsymbol{r}\\
H_1&: \boldsymbol{\beta_{j}} \neq \boldsymbol{r}
\end{cases}$$


Si $\gamma_{j}$ es el j-esimo coeficiente diagonal de la matriz  $\left ( X^{T} X \right )^{-1}$ y $\gamma_{j}>0$

Entonces el valor de t estadistico de prueba para cada $\beta_{j}$ es: 

$$t_{n-k}=\frac{\widehat\beta_{j} - \beta_{j} }{\sqrt{\sigma^{2} \gamma_{j}}}$$




<br>


### Ejemplo de aplicación de MCO y MCG en el pronóstico de sueldo como función de variables sociodemográficas



```{r}

library(lmtest)
library(lrmest)
library(tseries)
library(nortest)
##library(car)
library(sandwich)
library(lattice)
library(viridisLite)
library(leaps)

```


#### Importación y lectura de la data de salario como función de variables sociodemográficas

```{r}

wage_source <- "http://www.principlesofeconometrics.com/poe5/data/csv/cps5_small.csv"
wage_data <- read.csv(file = wage_source, sep = ",", dec = ".", header = TRUE)
print(head(wage_data, 10))

```


Definiciones de variables: <br>

black - = 1 si el encuestado se clasifica como raza negra <br>
educ - años de educación <br>
exper - experiencia potencial = edad - educación - 6 <br>
faminc - otros ingresos familiares, $<br>
female - = 1 si es mujer<br>
metro - = 1 si se encuentra en un área metropolitana<br>
midwest - = 1 si es región del medio oeste<br>
south - = 1 si es región sur<br>
wage - ingresos por hora, $<br>
west - = 1 si es región oeste<br>



Tengamos un vistazo rápido  de los datos con un reumen estadístico de las variables 

```{r}
print(summary(wage_data))
```


#### División de la data en train & test

```{r}

# Set seed for reproducibility
set.seed(123)

# Create an index for splitting the data
index <- sample(2, nrow(wage_data), replace = TRUE, prob = c(0.8, 0.2))

# Split the data into training and test sets
wage_train_data <- wage_data[index == 1, ]
wage_test_data <- wage_data[index == 2, ]

print(head(wage_test_data))

```


####  A. Las variables xi predictoras son linealmente indpendientes entre si, por lo que la matriz X es de rango completo


```{r}
panel.hist <- function(x, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE, breaks = 30)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, ...)
}
panel.abs_cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...){
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y, use = "complete.obs"))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = 2)
}
```



```{r}
pairs(wage_train_data[, c('educ','exper', 'faminc', 'wage')],
      diag.panel = panel.hist, 
      lower.panel = panel.smooth, #upper.panel = panel.cor, 
      col = "dodgerblue4", 
      pch = 21, 
      bg = adjustcolor("dodgerblue3", alpha = 0.2))
```


Los valores absolutos de la correlación son útiles para determinar la fuerza general de la relación lineal, independientemente de la dirección de la correlación.

También podemos estar interesados en verificar el mapa de calor de la matriz de correlación por separado 


```{r fig.width=8}
myPanel <- function(x, y, z, ...){
  lattice::panel.levelplot(x, y, round(z, 2), ...)  # Round the correlation values to two decimals
  my_text <- ifelse(!is.na(z), paste0(round(z, 2)), "")
  lattice::panel.text(x, y, my_text, cex = 0.8)  # Adjust the font size
}
# base colors: terrain.colors(), rainbow(), heat.colors(), topo.colors() or cm.colors()
# Viridis: viridis, magma, inferno, plasma
lattice::levelplot(cor(wage_train_data, use = "complete.obs"), panel = myPanel, 
                   col.regions = viridisLite::viridis(100),
  main =("Valor de Correlacion Lineal entre las variables Xi predictoras"), ylab = list(label = "Variables Xi predictoras"),
                               xlab = list(label = "Variables Xi predictoras"), scales = list(x = list(rot = 90)))  #)  # Rotate the x-axis labels by 90 degrees

```

Observamos que wage y educ tienen una correlación positiva. Esta es la correlación positiva más fuerte en el conjunto de datos.
south, midwest y west parecen estar negativamente correlacionados, sin embargo, es lo que se espera - son variables indicadoras de la ubicación geográfica, por lo que una observación solo puede tener una de estas variables con un valor de 1
1 a la vez.



### Modelo MCO1 

para encontrar el error y hacer las pruebas de las hipotesis planteadas como ciertas para los modelos lineales


```{r}
# Load libraries
library(stats)

# Fit linear model
olm_model1_wage_train_data <- lm(wage ~ black+educ+exper+faminc+female+metro+midwest+south, data = wage_train_data)

# View model summary
summary(olm_model1_wage_train_data)
```
El modelo resultante de aplicar MOC1 a la data de wage fue: 

$$\begin{aligned}
wage_i &= \beta_0 - \beta_1 black_i + \beta_2 educ_i + \beta_3 exper_i + \beta_4 faminc_i - \beta_5 female_i + \beta_6 metro_i - \beta_7 midwest_i - \beta_8 south_i + \varepsilon_i ; 
\\i = 1,...,N
\end{aligned}$$


####  Modelo resultante MCO1 para pronóstico de salario con base en datos raciales, de genero y geográficos

Empezemos específicando el modelo resultante de aplicar el MCO a la data de wage como función de las (9-1) variables predictoras xi que componen el dataset original. 




$$wage_i = -17.98 - 1.14*black_i + 2.54*educ_i + 0.19*exper_i + 0.00005*faminc_i - 5.74*female_i + 3.48*metro_i - 1.45*midwest_i - 1.22*south_i + \varepsilon_i  $$


Según el modelo estimado MCO1, se observa lo siguiente:

Los coeficientes son los esperados para las variables "educ", "exper":
- Un año más de educación representa en promedio 2.54 más de ganancia 
- Un año más de experiencia representa en promedio 0.19 más de ganancia 

El coeficiente de la variable "metro" también es el esperado:
- Vivir en un área metropolitana representa en promedio 3.48 más de ganancia con respecto a no vivir en un área metropolitana 


Para los coeficientes regionales de las variables "west" y "midwest", dado que solo una de ellas es significativa o "linealmente independiente", el programa tomó solo una de ellas en la ecuación lineal del modelo MCO. 
- Vivir en un área "west" o "midwest" representa en promedio 1.4 menos de ganancia con respecto a no vivir en un área "west" o "midwest"


Para los coeficientes regionales de la variable "south"
- Vivir en un área "south" representa en promedio 1.22 menos de ganancia con respecto a no vivir en un área "south"


El signo del coeficiente de la variable "female" es negativo y significativo, lo que indica una posible discriminación en la fuerza laboral (cabe recalcar que este es solo el modelo inicial, por lo que aún no podemos estar seguros).
- Ser "Female" representa en promedio 5.7 menos de ganancia con respecto a no ser "Female"


El signo del coeficiente de la variable "black" es negativo, pero no tan grande como Female
- Ser "Black" representa en promedio 1.14 menos de ganancia con respecto a no ser "Black"


#### Evaluación de la significancia de los estimadores $\beta$ del modelo MCO1


Queremos probar por separado la hipótesis de que cada coeficiente sea significativo a través de la prueba t de student que se presentó arriba


$$\begin{cases}
H_0&: \boldsymbol{\beta_{j}} = \boldsymbol{r}\\
H_1&: \boldsymbol{\beta_{j}} \neq \boldsymbol{r}
\end{cases}$$


```{r}
print(round(coef(summary(olm_model1_wage_train_data)), 4))
```


#### Valores de los estimadores $\beta$ del modelo MCO1 a 90 y 95% de confianza

```{r}
#install.packages("coefplot")
library(coefplot)

```



```{r}
# Get coefficients and confidence intervals
coef_summary <- summary(olm_model1_wage_train_data)$coefficients[, c("Estimate", "Std. Error")]
conf_intervals <- confint(olm_model1_wage_train_data)

# Combine coefficients and confidence intervals
coef_summary <- cbind(coef_summary, conf_intervals)

# Plot coefficients with confidence intervals
coefplot::coefplot(olm_model1_wage_train_data, coef.summary = coef_summary, 
                   main = "Coefficients and Confidence Intervals")

```



#### Prueba de hipotesis global para el modelo MCO1

Recordar la prueba de hipotesis F de fisher sobre los errores explicados vs no explicados por el modelo



$$F = \dfrac{ \left(\widehat{\boldsymbol{\beta}}_{OLS}- \beta^* \right)^\top \left[\left( \mathbf{X}^\top \mathbf{X}  \right)\right]^{-1} \left( \widehat{\boldsymbol{\beta}}_{OLS}- \beta^* \right)}{\widehat{\epsilon}^2}  \sim F_{(K, N - K)} $$


Esta es la prueba de hipótesis conjunta para la significancia de múltiples coeficientes, aplicada a todos los coeficientes del modelo MCO1:

$$\begin{cases}
H_0&: \beta_1 = \beta_2 = ... = \beta_k = 0 \\
H_1&: \beta_{j} \neq 0, \quad \text{for some } j
\end{cases}$$



```{r}
print(car::linearHypothesis(olm_model1_wage_train_data, c("black=0", "educ=0", "exper=0",  "faminc=0" ,  "female=0",  "metro=0",  "midwest=0",  "south=0")))
```

Dado que el valor p es menor que 0.05 decido que tenemos sifuciente videncia para rechazar la HO y por lo tanto decir que los coeficientes $\beta$ del modelo MCO1 son diferentes de cero




### Modelo MCO2 (removiendo las variables que no resultaron significatrivas en el MCO1 "original" que incluía todas las variables predictoras xi del conjunto de datos como variables predictoras)

Para construir el MCO2 se removerán las variables cuyos coeficientes p en la prueba t del modelo MCO1 sean mayores a 0.05, es decir las variables no significativas para el modelo MCO1, que en este caso eran: black, midwest y south.


```{r}
# Load libraries
library(stats)

# Fit linear model
olm_model2_wage_train_data <- lm(wage ~ educ+exper+faminc+female+metro, data = wage_train_data)

# View model summary
summary(olm_model2_wage_train_data)
```

El modelo resultante de aplicar MOC2 a la data de wage fue: 

$$\begin{aligned}
wage_i &= \beta_0 - \beta_1 educ_i + \beta_2 exper_i + \beta_3 faminc_i - \beta_4 female_i + \beta_5 metro_i + \varepsilon_i  
\\i = 1,...,N
\end{aligned}$$


####  Modelo resultante MCO2 para pronóstico de salario con base en datos raciales, de genero y geográficos

Empezemos específicando el modelo resultante de aplicar el MCO2 a la data de wage fomo función de las 5 variables predicoras xi que resultaron significativas. 


```{r}
print(round(coef(summary(olm_model2_wage_train_data)), 4))
```


$$wage_i = -19.27 + 2.55*educ_i + 0.19*exper_i + 0.00005*faminc_i - 5.90*female_i + 3.68*metro_i + \varepsilon_i   $$
Se observa que: <br>

- El valor del coeficiente del intercepto $\beta_0$  disminuyó ~1.8 menos que el valor del $\beta_0$ del MCO1. 
Esto podria se el resultado de que el nuevo  $\beta_0$ considerará las variables no significativas en el modelo MCO1 (black, midwest & south) pero que en general disminuían el valor del wage 
- Todos los demas coeficientes del modelo MOC2 se mantuvieron prácticamente iguales al valor dado en el MCO1


#### Valores de los estimadores $\beta$ del modelo MCO2 a 90 y 95% de confianza



```{r}
# Get coefficients and confidence intervals
coef_summary_lm_model2_wage_train_data <- summary(olm_model2_wage_train_data)$coefficients[, c("Estimate", "Std. Error")]
conf_intervals_lm_model2_wage_train_data <- confint(olm_model2_wage_train_data)

# Combine coefficients and confidence intervals
coef_summary_lm_model2_wage_train_data <- cbind(coef_summary_lm_model2_wage_train_data, conf_intervals_lm_model2_wage_train_data)

# Plot coefficients with confidence intervals
coefplot::coefplot(olm_model2_wage_train_data, coef.summary = coef_summary_lm_model2_wage_train_data, 
                   main = "Coefficients and Confidence Intervals")

```






#### Prueba de hipotesis global para el modelo MCO2


Esta es la prueba de hipótesis conjunta para la significancia de múltiples coeficientes, aplicada a todos los coeficientes del modelo MCO:

$$\begin{cases}
H_0&: \beta_1 = \beta_2 = ... = \beta_k = 0 \\
H_1&: \beta_{j} \neq 0, \quad \text{for some } j
\end{cases}$$



```{r}
print(car::linearHypothesis(olm_model2_wage_train_data, c("educ=0", "exper=0",  "faminc=0" ,  "female=0",  "metro=0")))
```

Dado que el valor p es menor que 0.05 decido que tenemos sifuciente videncia para rechazar la HO y por lo tanto decir que los coeficientes $\beta$ del modelo MCO2 son diferentes de cero




##### Los supuestos de GAUSS-MARKOV sobre el error en los modelos lineales 
<br>

En general en los modelos lineales se asumen los siguientes enunciados como ciertos:

 A. Las variables xi predictoras son linealmente indpendientes entre si, por lo que la matriz X es de rango completo <br>
 B. Los errores siguen una distribución normal 
 
 $${\varepsilon}\sim N(\mathbf{0}, \sigma^2\Omega)$$
 
 C. El valor esperado del error dado los valores de la matriz X es cero 
 $$\mathbb{E} \left( \boldsymbol{\varepsilon} | \mathbf{X}\right) = \boldsymbol{0}$$
 D. La varianza del error dado los valores de la matriz X puede calcularse como: 
 
 
 $$\mathbb{V}{\rm ar}\left( \boldsymbol{\varepsilon} | \mathbf{X} \right)= \mathbb{E} \left( \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\top \right)$$
 
 
 es decir, 
 
$$ \mathbb{V}{\rm ar}\left( \boldsymbol{\varepsilon} | \mathbf{X} \right) = \mathbb{E} \left( \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\top \right)= \boldsymbol{\Sigma} = \sigma_\epsilon^2 \mathbf{\Omega}$$


Donde ${\Omega}$ es una matriz cuadrada, simétrica y definida positiva de tamaño N × N. Este modelo permite que los errores sean heterocedásticos o autocorrelacionados (o ambos) y a menudo se denomina caso especial del modelo lineal generalizado (GLM).



Si ${\Omega}=I$, entonces el GMLR es simplemente el modelo MCO que hemos estado discutiendo al momento.


$$ {\Omega}= \begin{pmatrix}
1 & 0 & 0 & ..  0\\ 
0 &  1& 0 & ..  0\\
0 &  0& 1 & ..  0\\ 
0 & 0 & 0 &  ..  1 
\end{pmatrix}$$ 




### Evaluación de los error del modelo MCO2 (verificación de supuestos de GAUSS-MARKOV)


Una vez teniendo el modelo MCO2 en el que todas las variables predcitoras xi son significativas se procederá a hacer las diferentes pruebas de hipitesis al error generado con el modelo MCO2 aplicado a los datos de entrenamiento, es decir, las pruebas de 
- Normalidad de los errores
- No autocorrelación de orden 1 y ordenes superiroes de los errores 
- Homocerasticidad de errores


#### Evaluación general de los error del modelo MCO2



```{r}
# Define the plot layout matrix:
layout_mat <- matrix(c(1, 1, 2, 2, 3, 3, 3, 3), 
                     nrow = 2, byrow = TRUE)
# print(layout_mat)
layout(layout_mat)
plot(olm_model2_wage_train_data$fitted.values, olm_model2_wage_train_data$residuals, type = "p", 
     pch = 21, bg = "cornflowerblue", main = "Residuals vs Fitted", 
     ylab = "residuals", xlab = "fitted values", cex = 1.5)
hist(olm_model2_wage_train_data$residuals, col = "cornflowerblue", 
     breaks = 30, main = "Residual Histogram")
qqnorm(olm_model2_wage_train_data$residuals, main = "Q-Q plot of residuals", 
       pch = 21, bg = "cornflowerblue", cex = 1.5)
qqline(olm_model2_wage_train_data$residuals, col = "red", lwd = 2)
```


En general se observa que el error sigue un comportamiento aproximadamente normal y centraod en cero, procedamos a llevar a cabo cada prueba de hipotesis por separado: 


#### Test de Homocedasticidad de errores del modelo MCO2 (Test Breusch-Pagan)

$$\begin{cases}
H_0&: \text{residuals are homoskedastic}\\
H_1&: \text{residuals are heteroskedastic}
\end{cases}$$


```{r}
# Breusch–Pagan Test

print(lmtest::bptest(olm_model2_wage_train_data))
```


En este caso el valor de p< 0.05, por lo tanto rechazamos la hipótesis nula de que los residuos son homocedásticos. Esto significa que los residuos son heterocedásticos.





#### Test de Autocorrelación de errores del modelo MCO2 (Test Durbin-Watson, autocorrelación de 1er orden)

$$\begin{cases}
H_0&:\text{the errors are serially uncorrelated}\\
H_1&:\text{the errors are autocorrelated (the exact order of the autocorrelation depends on the test carried out)}
\end{cases}$$



```{r}

# Durbin–Watson Test
print(lmtest::dwtest(olm_model2_wage_train_data, alternative = "two.sided"))

```

El estadístico de DW está cerca de 2 (esto se puede verificar en R, ya que el valor p asociado es mayor a 0.05), por lo que no rechazamos la hipótesis nula de que no existe correlación serial de orden 1.



#### Test de Autocorrelación de Parcial errores del modelo MCO2 (Test PACF, autocorrelación de orden superior)


```{r}
pacf(olm_model2_wage_train_data$residuals)
```

Como podemos ver, no tenemos motivos para rechazar la hipótesis nula de autocorrelación en ninguno de los casos (excepto quizá para los errores a lag 20 y 27)

A partir de estos resultados de la prueba, podemos concluir que los residuos no están autocorrelacionados



#### Test de Normalidad de los errores del modelo MCO2 (Test Jarque-Bera)

$$\begin{cases}
H_0&:\text{residuals follow a normal distribution}\\
H_1&:\text{residuals do not follow a normal distribution}
\end{cases}$$


```{r}
 tseries::jarque.bera.test(olm_model2_wage_train_data$residuals)
```

A partir de estos resultados de la prueba, podemos decir que tenemos suficiente información para rechazar H0 y por lo tanto concluir que los residuos del modelo MCO2 NO se distribuyen normalmente :(



### Modelo MCO3 (removiendo las variables que no resultaron significatrivas en el MCO1 original que incluía todas las variables predictoras xi del conjunto de datos como variables predictoras + Logaritmo de variable dependiente wage como medida para lograr normalidad en error)

Para construir el MCO3 se removerán las variables cuyos coeficientes p en la prueba t del modelo MCO1 sean mayores a 0.05, es decir las variables no significativas para el modelo MCO1, que en este caso eran: black, midwest y south. Aedemás el modelo se hará tomadno como variable dependiente el log(wage)

```{r}
# Load libraries
library(stats)

# Fit linear model
olm_model3_wage_train_data <- lm(log(wage) ~ educ+exper+faminc+female+metro, data = wage_train_data)

# View model summary
summary(olm_model3_wage_train_data)
```

El modelo resultante de aplicar MOC3 a la data de wage fue: 

$$\begin{aligned}
log(wage_i) &= \beta_0 - \beta_1 educ_i + \beta_2 exper_i + \beta_3 faminc_i - \beta_4 female_i + \beta_5 metro_i + \varepsilon_i  
\\i = 1,...,N
\end{aligned}$$


####  Modelo resultante MCO3 para pronóstico de salario con base en datos raciales, de genero y geográficos

Empezemos específicando el modelo resultante de aplicar el MCO3 a la data de log(wage) como función de las 5 variables predictoras xi que resultaron significativas. 


```{r}
print(round(coef(summary(olm_model3_wage_train_data)), 4))
```


$$log(wage_i) = 1.27 + 0.11*educ_i + 0.008*exper_i + 0.000007*faminc_i - 0.22*female_i + 0.13*metro_i + \varepsilon_i   $$

Se observa que:
El valor de los  coeficiente se ajusto a la escala logaritmica
Los errores aparentan estar más cercanos y centrados alrededor del cero


#### Valores de los estimadores $\beta$ del modelo MCO3 a 90 y 95% de confianza



```{r}
# Get coefficients and confidence intervals
coef_summary_lm_model3_wage_train_data <- summary(olm_model3_wage_train_data)$coefficients[, c("Estimate", "Std. Error")]
conf_intervals_lm_model3_wage_train_data <- confint(olm_model3_wage_train_data)

# Combine coefficients and confidence intervals
coef_summary_lm_model3_wage_train_data <- cbind(coef_summary_lm_model3_wage_train_data, conf_intervals_lm_model3_wage_train_data)

# Plot coefficients with confidence intervals
coefplot::coefplot(olm_model3_wage_train_data, coef.summary = coef_summary_lm_model3_wage_train_data, 
                   main = "Coefficients and Confidence Intervals")

```



#### Prueba de hipotesis global para el modelo MCO3


Esta es la prueba de hipótesis conjunta para la significancia de múltiples coeficientes, aplicada a todos los coeficientes del modelo MCO:

$$\begin{cases}
H_0&: \beta_1 = \beta_2 = ... = \beta_k = 0 \\
H_1&: \beta_{j} \neq 0, \quad \text{for some } j
\end{cases}$$



```{r}
print(car::linearHypothesis(olm_model3_wage_train_data, c("educ=0", "exper=0",  "faminc=0" ,  "female=0",  "metro=0")))
```

Dado que el valor p es menor que 0.05 decido que tenemos sifuciente videncia para rechazar la HO y por lo tanto decir que los coeficientes $\beta$ del modelo MCO3 son diferentes de cero





#### Evaluación general de los error del modelo MCO3 Log(wage)


```{r}
# Define the plot layout matrix:
layout_mat <- matrix(c(1, 1, 2, 2, 3, 3, 3, 3), 
                     nrow = 2, byrow = TRUE)
# print(layout_mat)
layout(layout_mat)
plot(olm_model3_wage_train_data$fitted.values, olm_model3_wage_train_data$residuals, type = "p", 
     pch = 21, bg = "cornflowerblue", main = "Residuals vs Fitted", 
     ylab = "residuals", xlab = "fitted values", cex = 1.5)
hist(olm_model3_wage_train_data$residuals, col = "cornflowerblue", 
     breaks = 30, main = "Residual Histogram")
qqnorm(olm_model3_wage_train_data$residuals, main = "Q-Q plot of residuals", 
       pch = 21, bg = "cornflowerblue", cex = 1.5)
qqline(olm_model3_wage_train_data$residuals, col = "red", lwd = 2)
```
En general de las gráficas del error del modelo MCO3 se observa que: 

Residual vs. fitted plot: En el gráfico de residuos vs. valores ajustados, los residuos parecen tener una varianza constante, aunque hay algunos puntos que tienen valores de residuos grandes para valores ajustados bajos, pero esos puntos no constituyen la mayoría (la prueba de heterocedasticidad nos ayudará a determinar si su varianza es la misma en todas las observaciones).


Histograma de residuos: En el histograma de residuos, los residuos parecen ser normales, aunque el histograma parece tener una cola derecha un poco más larga.


Gráfico Q-Q de residuos: Los residuos en el gráfico Q-Q parecen caer a lo largo de una línea recta con los cuantiles teóricos de una distribución normal, excepto por un punto en el extremo derecho (que probablemente sea un valor atípico).



#### Test de Normalidad de los errores del modelo MCO3 (Test Jarque-Bera)

$$\begin{cases}
H_0&:\text{residuals follow a normal distribution}\\
H_1&:\text{residuals do not follow a normal distribution}
\end{cases}$$



```{r}
 tseries::jarque.bera.test(olm_model3_wage_train_data$residuals)
```

Esto indica que el aplicar la transformaciñon de logaritmo a la varible dependiente wage logró que se corrigiera la NO normalidad de los errores en el modelo MCO




#### Test de Homocedasticidad de errores del modelo MCO3 (Test Breusch-Pagan)

$$\begin{cases}
H_0&: \text{residuals are homoskedastic}\\
H_1&: \text{residuals are heteroskedastic}
\end{cases}$$


```{r}
# Breusch–Pagan Test

print(lmtest::bptest(olm_model3_wage_train_data))
```

En este caso el valor de (sigue siendo) p< 0.05, por lo tanto rechazamos la hipótesis nula de que los residuos son homocedásticos. Esto significa que los residuos son heterocedásticos.


#### Test de Autocorrelación de Parcial errores del modelo MCO3

```{r}
pacf(olm_model3_wage_train_data$residuals)
```

Como podemos ver, no tenemos motivos para rechazar la hipótesis nula de autocorrelación en ninguno de los casos (excepto quizá para el error a lag 5)

A partir de estos resultados de la prueba, podemos concluir que los residuos no están autocorrelacionados (a excepción de la pequeña correlación que parece haber en el error a t-5)




### Modelo MCO4 (removiendo las variables que no resultaron significatrivas en el MCO1 original que incluía todas las variables predictoras xi del conjunto de datos como variables predictoras + Logaritmo de variable dependiente wage como medida para lograr normalidad en error + Agregando la variable educ*female para evaluar el efecto de un aó de edicación dado que se es female)

Para construir el MCO4 se removerán las variables cuyos coeficientes p en la prueba t del modelo MCO1 sean mayores a 0.05, es decir las variables no significativas para el modelo MCO1, que en este caso eran: black, midwest y south. + Se agregó la variable female*educ Aedemás el modelo se hará tomadno como variable dependiente el log(wage)



```{r}
# Load libraries
library(stats)

# Fit linear model
olm_model4_wage_train_data <- lm(log(wage) ~ educ+exper+faminc+female+metro+ female*educ, data = wage_train_data)

# View model summary
summary(olm_model4_wage_train_data)
```

Se observa como agregar la variable female*educ no mejoró el R^2 ajustado además de que a un nivel de significancia $\alpha = 0.05$ la variable 
female*educ resulta NO ser significativa.



### El modelo General Lineal (GLS) o Modelo de Mínimos Cuadrados Generalizados (MCG)


##### Los supuestos de GAUSS-MARKOV en  el modelo General Lineal (GLR) o Modelo de Mínimos Cuadrados (MCG) Generalizados

<br>

En general el modelo MCG asume los siguientes enunciados como ciertos:

 A. Las variables xi predictoras son linealmente indpendientes entre si, por lo que la matriz X es de rango completo <br>
 B. Los errores siguen una distribución normal 
 $${\varepsilon}\sim N(\mathbf{0}, \sigma^2\Omega)$$
 
 C. El valor esperado del error dado los valores de la matriz X es cero 
 $$\mathbb{E} \left( \boldsymbol{\varepsilon} | \mathbf{X}\right) = \boldsymbol{0}$$
 D. La varianza del error dado los valores de la matriz X puede calcularse como: 
 
 
 
 
 $$\mathbb{V}{\rm ar}\left( \boldsymbol{\varepsilon} | \mathbf{X} \right)= \mathbb{E} \left( \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\top \right)$$
 es decir, 
 
$$ \mathbb{V}{\rm ar}\left( \boldsymbol{\varepsilon} | \mathbf{X} \right) = \mathbb{E} \left( \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\top \right)= \boldsymbol{\Sigma} = \sigma_\epsilon^2 \mathbf{\Omega}$$


Donde ${\Omega}$ es una matriz cuadrada, simétrica y definida positiva de tamaño N × N. Este modelo permite que los errores sean heterocedásticos o autocorrelacionados (o ambos) y a menudo se denomina caso especial del modelo lineal generalizado (GLM).



Si ${\Omega}=I$, entonces el GMLR es simplemente el modelo de regresión lineal múltiple simple que discutimos al comienzo de este capítulo.


$$ {\Omega}= \begin{pmatrix}
1 & 0 & 0 & ..  0\\ 
0 &  1& 0 & ..  0\\
0 &  0& 1 & ..  0\\ 
0 & 0 & 0 &  ..  1 
\end{pmatrix}$$ 


Si ${\Omega}$ es diagonal con elementos diagonales no constantes, entonces los términos de error no están correlacionados pero son heterocedásticos.


$${\Omega}= \begin{pmatrix}
\omega_{1}  & 0 & 0 & ..  0\\ 
0 &  \omega_{2}& 0 & ..  0\\
0 &  0& \omega_{3} & ..  0\\ 
0 & 0 & 0 &  ..  \omega_{n} 
\end{pmatrix}$$


Si ${\Omega}$ no es diagonal, entonces $Cov(\varepsilon_{i}, \varepsilon_{j})={\Omega_{ij}\neq 0}$ En econometría, las matrices de covarianza no diagonales se encuentran con mayor frecuencia en los datos de series temporales, con correlaciones más altas para las observaciones más cercanas en el tiempo (generalmente cuando i y j difieren en 1 o 2).


Si ${\Omega}$ no es diagonal y los elementos diagonales son constantes, entonces los errores están autocorrelacionados y homocedásticos.

$${\Omega}= \begin{pmatrix}
\sigma^{2}  & \rho_{12} & \rho_{13} & ..\rho_{1N}\\ 
\rho_{21}  &  \sigma^{2}& \rho_{23}  & ..\rho_{2N} \\
\rho_{31}  &  \rho_{32} & \sigma^{2} & ..\rho_{3N} \\ 
\rho_{41}  &  \rho_{42}  & \rho_{43}  &  ..\sigma^{2} 
\end{pmatrix}$$



Si ${\Omega}$ no es diagonal y los elementos diagonales no son constantes, entonces los errores están autocorrelacionados y heterocedásticos.


$${\Omega}= \begin{pmatrix}
\omega_{1}  & \rho_{12} & \rho_{13} & ..\rho_{1N}\\ 
\rho_{21}  &  \omega_{2}& \rho_{23}  & ..\rho_{2N} \\
\rho_{31}  &  \rho_{32} & \omega_{3} & ..\rho_{3N} \\ 
\rho_{41}  &  \rho_{42}  & \rho_{43}  &  ..\omega_{N} 
\end{pmatrix}$$


Y cuya función de minimización de error o función de costo a minimizar como función de los estimadores del modelo GLS es:

$$\left( \mathbf{Y} - \mathbf{X} \boldsymbol{\beta} \right)^\top \mathbf{\Omega}^{-1} \left( \mathbf{Y} - \mathbf{X} \boldsymbol{\beta} \right) \rightarrow \min_{\boldsymbol{\beta}}$$



##### Coeficientes ${\beta}_{GLS}$ del Modelo MCG


Y cuyos coeficientes son calculados con base en los datos de la muestra de la siguiente manera:


$$\begin{aligned}
\widehat{\boldsymbol{\beta}_{GLS}}  = \left( \mathbf{X}^\top \mathbf{\Omega}^{-1}  \mathbf{X}\right)^{-1} \mathbf{X}^\top \mathbf{\Omega}^{-1}  \mathbf{Y}
\end{aligned}$$



##### Propiedades de los coeficientes ${\beta}_{GLS}$ del Modelo Minimos Cuadrados Generalizados (MCG)

Y si se cumplen las condiciones de GAUSS-MARKOV entonces se dice que los coeficientes  ${\beta}_{GLS}$ son: 

- Insesgados: El valor esperado es igual al parámetro que está estimando

$$\mathbb{E} \left( \widehat{\boldsymbol{\beta}}_{OLS} \right)  = \boldsymbol{\beta}$$

- Consistentes: Si converge al valor del parámetro que está estimando a medida que el tamaño de la muestra tiende a infinito

- Eficientes: Si tiene la varianza más pequeña entre todos los estimadores insesgados




### Modelo MCG1 (correlacion del error 5)

```{r}
# Install 'nlme' package if you haven't already
#install.packages("nlme")

# Load the 'nlme' library
library(nlme)

# Fit genralized linear model
glm_1_wage_train_data <- gls(log(wage) ~ educ + exper + faminc + female + metro, correlation = corARMA(q = 5), method = "ML", data = wage_train_data)

# View model summary
summary(glm_1_wage_train_data)

```


```{r}
# Obtain the summary of the model
summary_glm1 <- summary(glm_1_wage_train_data)

# Extract the residual variance and total variance
residual_variance_glm1 <- summary_glm1$sigma^2
total_variance_glm1 <- sum((log(wage_train_data$wage) - mean(log(wage_train_data$wage)))^2)

# Calculate R-squared
R_squared_glm1 <- 1 - (residual_variance_glm1 / total_variance_glm1)

# Display R-squared
print(R_squared_glm1)
```



#### Valores de los estimadores $\beta$ del modelo MCG1 a 90 y 95% de confianza




```{r}
# Load necessary packages
library(nlme)

# Get coefficients and confidence intervals for GLS model
coef_summary_glm_1_wage_train_data <- as.data.frame(coef(summary(glm_1_wage_train_data)))
conf_intervals_glm_1_wage_train_data <- confint(glm_1_wage_train_data)

# Combine coefficients and confidence intervals
coef_summary_glm_1_wage_train_data <- cbind(coef_summary_glm_1_wage_train_data, conf_intervals_glm_1_wage_train_data)

# Print coefficients and confidence intervals
print(coef_summary_glm_1_wage_train_data)

```

```{r}
coef_summary_glm_1_wage_train_data <- as.data.frame(coef_summary_glm_1_wage_train_data)
coef_summary_glm_1_wage_train_data
```


```{r}
library(ggplot2)

# Extract relevant information for plotting
variables <- rownames(coef_summary_glm_1_wage_train_data)
coefficients_glm_1_wage_train_data <- coef_summary_glm_1_wage_train_data$Value
lower_bound_glm_1_wage_train_data <- coef_summary_glm_1_wage_train_data$"2.5 %"
upper_bound_glm_1_wage_train_data <- coef_summary_glm_1_wage_train_data$"97.5 %"

# Create a dataframe for plotting
plot_data <- data.frame(Variable = variables, Coefficient = coefficients_glm_1_wage_train_data, Lower = lower_bound_glm_1_wage_train_data, Upper = upper_bound_glm_1_wage_train_data)

# Plot coefficients with confidence intervals for GLS model using ggplot2
ggplot(plot_data, aes(y = Variable, x = Coefficient)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Lower, xmax = Upper), height = 0.2) +
  labs(title = "GLS glm_1_wage_train_data Model Coefficients and Confidence Intervals", x = "Coefficient", y = "Variable")


```



#### Prueba de hipotesis global para el modelo MCG1



$$F = \dfrac{ \left(\widehat{\boldsymbol{\beta}}_{GLS}- \beta^* \right)^\top \left[\left( \mathbf{X}^\top \mathbf{\Omega}^{-1} \mathbf{X}  \right)\right]^{-1} \left( \widehat{\boldsymbol{\beta}}_{GLS}- \beta^* \right)}{\widehat{\epsilon}^2}  \sim F_{(K, N - K)} $$


Esta es la prueba de hipótesis conjunta para la significancia de múltiples coeficientes, aplicada a todos los coeficientes del modelo MCG:

$$\begin{cases}
H_0&: \beta_1 = \beta_2 = ... = \beta_k = 0 \\
H_1&: \beta_{j} \neq 0, \quad \text{for some } j
\end{cases}$$



```{r}
print(car::linearHypothesis(glm_1_wage_train_data, c("educ=0", "exper=0",  "faminc=0" ,  "female=0",  "metro=0")))
```

Dado que el valor p es menor que 0.05 decido que tenemos sifuciente videncia para rechazar la HO y por lo tanto decir que los coeficientes $\beta$ del modelo MCG1 son diferentes de cero


####  Modelo resultante MCG1 para pronóstico de salario con base en datos raciales, de genero y geográficos

$$log(wage_i) = 1.24 + 0.11*educ_i + 0.008*exper_i + 0.000001*faminc_i - 0.22*female_i + 0.14*metro_i -0.052*\theta_1 + 0.045*\theta_2 +0.032*\theta_3 -0.063*\theta_4 -0.068*\theta_5    + \varepsilon_i   $$


####  Evaluación general del errror del Modelo  MCG1 

```{r}
par(mfrow = c(2, 2))

#
plot(olm_model3_wage_train_data$fitted.values, olm_model3_wage_train_data$residuals, main = "MCO3 Residuals vs Fitted")

#
plot(wage_train_data$educ, olm_model3_wage_train_data$residuals, main = bquote("MCO3 Residuals vs"~X[1]))

#
plot(glm_1_wage_train_data$fitted, glm_1_wage_train_data$residuals, col = "blue", main = "MCG1 Residuals vs Fitted")

#
plot(wage_train_data$educ, glm_1_wage_train_data$residuals, col = "blue", main = bquote("MCG1 Residuals vs"~X[1]))
```



#### Test de Normalidad de los errores del modelo MCG1 (Test Jarque-Bera)

$$\begin{cases}
H_0&:\text{residuals follow a normal distribution}\\
H_1&:\text{residuals do not follow a normal distribution}
\end{cases}$$



```{r}
 tseries::jarque.bera.test(glm_1_wage_train_data$residuals)
```
No se tiene evidencia suficiente para rechazar la hipotesis nula del test JB por lo que se puede decir que los errores del modelo MCG1 siguen una distribución normal



#### Test de Homocedasticidad de errores del modelo MCG1 (Test Breusch-Pagan)

$$\begin{cases}
H_0&: \text{residuals are homoskedastic}\\
H_1&: \text{residuals are heteroskedastic}
\end{cases}$$


```{r}
# Breusch–Pagan Test

# Obtain residuals from the gls model
residuals_gls_1 <- residuals(glm_1_wage_train_data)

# Fit a linear regression model of squared residuals on the predictors
lm_resid_sq_1 <- lm(residuals_gls_1^2 ~ wage_train_data$educ + wage_train_data$exper + wage_train_data$faminc + wage_train_data$female + wage_train_data$metro)

# Perform the Breusch-Pagan test manually
lmtest::bptest(lm_resid_sq_1)
```




#### Test de Autocorrelación de Parcial errores del modelo MCG1



```{r}
pacf(glm_1_wage_train_data$residuals)
```



Nos encontramos entonces en el caso donde los errores no están correlacionados pero son heterocerastico, es decir en donde nuestra matriz de covarianza del error es del tipo:


$${\Omega}= \begin{pmatrix}
\omega_{1}  & 0 & 0 & ..  0\\ 
0 &  \omega_{2}& 0 & ..  0\\
0 &  0& \omega_{3} & ..  0\\ 
0 & 0 & 0 &  ..  \omega_{n} 
\end{pmatrix}$$



#### Tratamiento de heterocerasticidad en los errores. 

Tras detectar heterocedasticidad en los errores, se quisieraimponer una estructura a la matriz de covarianza residual y estimar los coeficientes mediante GLS. Si sabemos que no existe correlación serial en los errores, entonces la covarianza es diagonal. Esto conduce a un caso específico de GLS: mínimos cuadrados ponderados (WLS).

En realidad, no conocemos la forma real de la heterocedasticidad. Por lo tanto, incluso sabiendo que la matriz de covarianza es diagonal, esto no nos dice nada sobre los elementos diagonales, que podrían ser cualquiera de los siguientes ejemplos:


$$\begin{aligned}
\mathbf{\Sigma} &= \sigma^2 \cdot \text{diag}\left(X_{j,1}, X_{j,2},..., X_{j,N} \right) \quad \\
\mathbf{\Sigma} &= \sigma^2 \cdot \text{diag}\left(X_{j,1}^2, X_{j,2}^2,..., X_{j,N}^2 \right)\\
\mathbf{\Sigma} &= \sigma^2 \cdot \text{diag}\left(\sqrt{X_{j,1}}, \sqrt{X_{j,2}},..., \sqrt{X_{j,N}} \right), \text{ if } X_{j,i} \geq 0,\ \forall i = 1,...,N
\end{aligned}$$


Además, en una regresión múltiple, el patrón de heterocedasticidad puede depender de más de una variable explicativa; incluso podría estar relacionado con variables no incluidas en el modelo. Entonces, ¿cómo seleccionamos la forma más probable de heterocedasticidad?


Es a partir de los errores de los MCO que se obtiene una ponderación que sera el número que dividirá a todos los valores de covarianza heterocerasticos 

$$\begin{aligned}
\sigma^2_i &= \exp\left( \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} \right)\\
&= \sigma^2 \exp\left(\alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} \right),\ \text{ where } \exp\left( \alpha_0 \right) = \sigma^2
\end{aligned}$$


Modelar la varianza como una función exponencial de algunas variables explicativas (como α0+α1Z1,i+...+αmZm,i) sugiere una forma funcional para explicar las varianzas variables.

Inicialmente, σi2=exp(α0+α1Z1,i+...+αmZm,i) define la varianza (σi2) como una función exponencial de los predictores (Z1,i,Z2,i,...,Zm,i) con parámetros (α0,α1,...,αm).


Tomar logaritmos de ambos lados y agregar/eliminar el residuo de OLS da como resultado:


$$\log(\sigma^2_i) = \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i}  \pm \log(\widehat{\epsilon}^2_i)$$

Tomar logaritmos de ambos lados de la ecuación ayuda a linealizar la relación. Convierte la relación multiplicativa entre la varianza y los predictores en una aditiva.

Esto conduce a log⁡(σi2)=α0+α1Z1,i+...+αmZm,i.

Agregar o eliminar los residuos de OLS (Ordinary Least Squares) de la ecuación produce log⁡(ϵi2)=α0+α1Z1,i+...+αmZm,i±log(ϵi2/σi2).


Esto se puede simplificar como: 

$$\begin{aligned}
\log(\widehat{\epsilon}^2_i) &= \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} + \log \left( \dfrac{\widehat{\epsilon}^2_i}{\sigma^2_i} \right)\\
&= \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} + v_i
\end{aligned}$$


Esta ecuación se simplifica a log⁡(ϵi2)=α0+α1Z1,i+...+αmZm,i+vi, donde vi es un término de error introducido.


El término de error introducido vi captura la diferencia entre la varianza real y la varianza predicha por el modelo.



Se estiman los coeificentes (α0,α1,...,αm) usando MCO para cuantificar como los predictores  (Z1,i,Z2,i,...,Zm,i) se relacionan con la variabilidad de los reisduales

Las propiedades de este modelo dependen de las propiedades del término de error introducido vi. En muestras más grandes, se espera que este término de error sea más cercano a lo que esperamos del término de error (homocedástico con media cero).


### El procedimiento del método de GLS ó MCG para el caso de errores heterocerasticos 


1. Llevar a cabo la regesion $\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}$ usando los MCO
2. Usar los residuos de los MCO $\widehat{\boldsymbol{\varepsilon}}_{OLS}$ como $\log(\epsilon_i^2)$


3. Calcular $\log(\epsilon_i^2) = \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} + v_i$

En la práctica, utilizamos las mismas variables del conjunto $\mathbf{X}$, a menos que sepamos con certeza que existen variables explicativas adicionales que podrían determinar la heterocedasticidad.

4. Se calcula el valor de la variable hi que se usará como una espeice de "ponderador" de varianzas que tiene como intención hacer de dichas varianzas heterocerasticas, lo más homocerasticas posibles, en este caso, lo mas cercanas y parecidas a la unidad

$$\widehat{h}_i = \exp\left(\widehat{\log(\epsilon_i^2)}\right)$$

5. Se Llevaa a cabo de nuevo la regesion $\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}$ usando ahora  WLS

$$\omega_i^{-1} = 1/\sqrt{\widehat{h}_i}$$

$$\mathbf{\Psi}^\top = \mathbf{\Psi} = \text{diag}\left( 1/\sqrt{\widehat{h}_1}, ..., 1/\sqrt{\widehat{h}_N}\right)$$

Lo que implica que nuestro modelo ahora es del tipo:

$$Y_i / \sqrt{\widehat{h}_i} = \beta_0 \cdot \left(1/\sqrt{\widehat{h}_i} \right) + \beta_1 \cdot \left(X_{1,i} / \sqrt{\widehat{h}_i} \right) + ... + \beta_k \cdot \left(X_{k,i} / \sqrt{\widehat{h}_i} \right) + \epsilon_i/\sqrt{\widehat{h}_i}$$


Nuestro modelo ya no contiene una constante -β0 ahora se usa para la nueva variable (no constante) $1/\sqrt{\widehat{h}_i} \neq 1$


#### Weighted Least Square (WLS) para tratar temas de herocerasticidad de errores (MCO1)


Entonces se calculan los 
$$\log(\epsilon_i^2)$$:


```{r}

# Extract residuals from the model
residuals_model_mco1 <- residuals(olm_model1_wage_train_data)

residuals_model_mco1_dataframe <- data.frame(log_e2 = log(residuals_model_mco1^2), wage_train_data$educ, wage_train_data$exper, wage_train_data$faminc, wage_train_data$female, wage_train_data$metro)

head(residuals_model_mco1_dataframe)



```



```{r}
dim(residuals_model_mco1_dataframe)
```



```{r}
log_e2 = log(residuals_model_mco1^2)
length(log_e2)

```


Y se crea el modelo lineal de los log de errores 


$$\begin{aligned}
\log(\widehat{\epsilon}^2_i) &= \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} + \log \left( \dfrac{\widehat{\epsilon}^2_i}{\sigma^2_i} \right)\\
&= \alpha_0 + \alpha_1 Z_{1,i} + ... + \alpha_m Z_{m,i} + v_i
\end{aligned}$$


```{r}
residual_linear_model_mco1<- lm(log_e2 ~  wage_train_data$educ+ wage_train_data$exper+wage_train_data$faminc+wage_train_data$female+wage_train_data$metro, data = residuals_model_mco1_dataframe)

residual_linear_model_mco1


```



```{r}
length(residual_linear_model_mco1$fitted.values)
```


Y se calcula el "factor de corrección de heterocerasticidad" $\omega_i^{-1} = 1/\sqrt{\widehat{h}_i}$ 

$$\widehat{h}_i = \exp\left(\widehat{\log(\epsilon_i^2)}\right)$$

```{r}
h_est_model_mco1 <- exp(residual_linear_model_mco1$fitted.values)
length(h_est_model_mco1)
```



Se arma el data frame para aplicar el "factor de corrección de heterocerasticidad" $\omega_i^{-1} = 1/\sqrt{\widehat{h}_i}$


Es decir: 
$$Y_i / \sqrt{\widehat{h}_i} = \beta_0 \cdot \left(1/\sqrt{\widehat{h}_i} \right) + \beta_1 \cdot \left(X_{1,i} / \sqrt{\widehat{h}_i} \right) + ... + \beta_k \cdot \left(X_{k,i} / \sqrt{\widehat{h}_i} \right) + \epsilon_i/\sqrt{\widehat{h}_i}$$

Y entonces se necesita formar el data frame

$$Y_i =  \ (X_{1,i}) + \ (X_{2,i}), ... \ + (X_{k,i})$$

```{r}

data_mat_glm_1_wage_train_data <- data.frame(glm_1_wage_train_data$fitted, wage_train_data$educ, 
    wage_train_data$exper,  wage_train_data$faminc ,wage_train_data$female, wage_train_data$metro)

head(data_mat_glm_1_wage_train_data)
```

Agregando el $\beta_0$
$$Y_i = \beta_0 +  \ (X_{1,i}) + \ (X_{2,i}), ... \ + (X_{k,i})$$

```{r}
data_weighted_glm_1_wage_train_data = data.frame(data_mat_glm_1_wage_train_data / sqrt(h_est_model_mco1), weighted_intercept = 1 / sqrt(h_est_model_mco1))

head(data_weighted_glm_1_wage_train_data)
```



```{r}
dim(data_weighted_glm_1_wage_train_data)
```


Calculando el "factor de corrección de heterocerasticidad"

$$\omega_i^{-1} = 1/\sqrt{\widehat{h}_i}$$

```{r}
weighted_intercept = 1 / sqrt(h_est_model_mco1)
length(weighted_intercept) 
```



```{r}
weights_varFunc <- varFixed(~ 1/h_est_model_mco1)
weights_varFunc

```



```{r}
weights_varFunc
```



### Modelo MCG2_2 (correlacion del error 5 + tratamiento de heterocerasticidad de errores)


```{r}
# Assuming data_mat_glm_1_wage_train_data is properly constructed
data_weighted_glm_1_wage_train_data <- data.frame(
  fitted = data_mat_glm_1_wage_train_data[, 1],  # Assuming the first column is 'fitted'
  educ = wage_train_data$educ,
  exper = wage_train_data$exper,
  faminc = wage_train_data$faminc,
  female = wage_train_data$female,
  metro = wage_train_data$metro
)
data_weighted_glm_1_wage_train_data$weighted_intercept <- 1 / sqrt(h_est_model_mco1)

# Check the structure and head of data_weighted_glm_1_wage_train_data again
str(data_weighted_glm_1_wage_train_data)
head(data_weighted_glm_1_wage_train_data)

```



```{r}
glm_2_2_wage_train_data <- gls(log(fitted) ~ educ + exper + faminc + female + metro, 
                                weights = weights_varFunc,
                                corARMA(p = 5),
                                method = "ML", 
                                data = data_weighted_glm_1_wage_train_data)


summary(glm_2_2_wage_train_data)

```



```{r}

print(round(coef(summary(glm_2_2_wage_train_data)), 5))
```


Se observa claramente como se tiene el menor error estandar en los errores comparado con el MGG1 y el MCO3


####  Modelo resultante MCG2 para pronóstico de salario con base en datos raciales, de genero y geográficos

$$log(wage_i) = 0.54 + 0.033*educ_i + 0.0025*exper_i + 0.0000003*faminc_i - 0.068*female_i + 0.045*metro_i -0.030*\theta_1 + 0.043*\theta_2 +0.0021*\theta_3 -0.0037*\theta_4 -0.009*\theta_5    + \varepsilon_i   $$


#### Valores de los estimadores $\beta$ del modelo MCG2 a 90 y 95% de confianza




```{r}
# Load necessary packages
library(nlme)

# Get coefficients and confidence intervals for GLS model
coef_summary_glm_2_2_wage_train_data <- as.data.frame(coef(summary(glm_2_2_wage_train_data)))
conf_intervals_glm_2_2_wage_train_data <- confint(glm_2_2_wage_train_data)

# Combine coefficients and confidence intervals
coef_summary_glm_2_2_wage_train_data <- cbind(coef_summary_glm_2_2_wage_train_data, conf_intervals_glm_2_2_wage_train_data)

# Print coefficients and confidence intervals
print(coef_summary_glm_2_2_wage_train_data)

```

```{r}
coef_summary_glm_2_2_wage_train_data <- as.data.frame(coef_summary_glm_2_2_wage_train_data)
coef_summary_glm_2_2_wage_train_data
```


```{r}
library(ggplot2)

# Extract relevant information for plotting
variables <- rownames(coef_summary_glm_1_wage_train_data)
coefficients_glm_2_2_wage_train_data <- coef_summary_glm_2_2_wage_train_data$Value
lower_bound_glm_2_2_wage_train_data <- coef_summary_glm_2_2_wage_train_data$"2.5 %"
upper_bound_glm_2_2_wage_train_data <- coef_summary_glm_2_2_wage_train_data$"97.5 %"

# Create a dataframe for plotting
plot_data <- data.frame(Variable = variables, Coefficient = coefficients_glm_2_2_wage_train_data, Lower = lower_bound_glm_2_2_wage_train_data, Upper = upper_bound_glm_2_2_wage_train_data)

# Plot coefficients with confidence intervals for GLS model using ggplot2
ggplot(plot_data, aes(y = Variable, x = Coefficient)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Lower, xmax = Upper), height = 0.2) +
  labs(title = "GLS glm_2_2_wage_train_data Model Coefficients and Confidence Intervals", x = "Coefficient", y = "Variable")


```


#### Calculando los residuos del modelo MCG2_2 (aplicando el escalado de matriz de varianza)


```{r}
errors_mcg2_2 <- 1 / sqrt(h_est_model_mco1) * glm_2_2_wage_train_data$residuals
head(errors_mcg2_2,5)

```


```{r}
length(errors_mcg2_2)
```



```{r}
par(mfrow = c(2, 2))

#
plot(glm_1_wage_train_data$fitted, glm_1_wage_train_data$residuals, col = "blue", main = "MCG1 Residuals vs Fitted")

#
plot(wage_train_data$educ, glm_1_wage_train_data$residuals, col = "blue", main = bquote("MCG1 Residuals vs"~X[1]))

#
plot(glm_2_2_wage_train_data$fitted, glm_2_2_wage_train_data$residuals, col = "blue", main = "MCG2 Residuals vs Fitted")

#
plot(wage_train_data$educ, glm_2_2_wage_train_data$residuals, col = "blue", main = bquote("MCG2 Residuals vs"~X[1]))

```


```{r}
hist(glm_2_2_wage_train_data$residuals)
```


Observamos claramente que la magnitud de los residuos del modelo GLM2_2/MCG2_2 es menor que el MCO1.




#### Test de Normalidad de los errores del modelo MCG2 (Test Jarque-Bera)

$$\begin{cases}
H_0&:\text{residuals follow a normal distribution}\\
H_1&:\text{residuals do not follow a normal distribution}
\end{cases}$$


```{r}
 tseries::jarque.bera.test(glm_2_2_wage_train_data$residuals)
```
No se tiene evidencia suficiente para rechazar la hipotesis nula del test JB por lo que se puede decir que los errores del modelo MCG1 siguen una distribución normal




#### Test de Homocedasticidad de errores del modelo MCG2_2 (Test Breusch-Pagan)

$$\begin{cases}
H_0&: \text{residuals are homoskedastic}\\
H_1&: \text{residuals are heteroskedastic}
\end{cases}$$


residuals_gls son los residuos obtenidos de su modelo gls.
lm_resid_sq ajusta un modelo de regresión lineal donde los residuos al cuadrado se regresan a los predictores (los mismos predictores utilizados en su modelo original).
Finalmente, se utiliza la función bptest de lmtest para realizar la prueba de Breusch-Pagan en este modelo de regresión.


```{r}

# Breusch–Pagan Test

# Obtain residuals from the gls model
residuals_gls_2_2 <- residuals(glm_2_2_wage_train_data)

# Fit a linear regression model of squared residuals on the predictors
lm_resid_sq_2_2 <- lm(residuals_gls_2_2^2 ~ wage_train_data$educ + wage_train_data$exper + wage_train_data$faminc + wage_train_data$female + wage_train_data$metro)

# Perform the Breusch-Pagan test manually
lmtest::bptest(lm_resid_sq_2_2)

```






### Aplicación de los modelos MCO y MCG para pronóstico de wage en la data de test 


#### Aplicación de modelo MCO1

```{r}
# Predict wages using the test data
wage_predicted_olm_model1 <- predict(olm_model1_wage_train_data, newdata = wage_test_data)

# Calculate Mean Absolute Percentage Error (MAPE)
MAPE_wage_predicted_olm_model1 <- mean(abs((wage_predicted_olm_model1 - wage_test_data$wage) / wage_test_data$wage)) * 100

MAPE_wage_predicted_olm_model1

```


```{r}
# Combine original test data with predicted values
combined_data_wage_predicted_olm_model1 <- cbind(wage_test_data, Predicted_Wage = wage_predicted_olm_model1)

# View the combined dataframe
head(combined_data_wage_predicted_olm_model1)

tail(combined_data_wage_predicted_olm_model1)
```



#### Aplicación de modelo MCO3

```{r}
# Predict wages using the test data
log_wage_predicted_olm_model3 <- predict(olm_model3_wage_train_data, newdata = wage_test_data)

wage_predicted_olm_model3<-exp(log_wage_predicted_olm_model3)

# Calculate Mean Absolute Percentage Error (MAPE)
MAPE_wage_predicted_olm_model3 <- mean(abs((wage_predicted_olm_model3 - wage_test_data$wage) / wage_test_data$wage)) * 100

MAPE_wage_predicted_olm_model3

```


```{r}
# Combine original test data with predicted values
combined_data_wage_predicted_olm_model3 <- cbind(wage_test_data, Predicted_Wage = wage_predicted_olm_model3)

# View the combined dataframe
head(combined_data_wage_predicted_olm_model3)

tail(combined_data_wage_predicted_olm_model3)
```



#### Aplicación de modelo MCG1

```{r}
# Predict wages using the test data
log_wage_predicted_glm_1<- predict(glm_1_wage_train_data, newdata = wage_test_data)

# Back-transform the predicted log wages to the original scale
wage_predicted_glm_1 <- exp(log_wage_predicted_glm_1)

# Calculate Mean Absolute Percentage Error (MAPE)
MAPE_Wage_predicted_glm_1 <- mean(abs((wage_predicted_glm_1 - wage_test_data$wage) / wage_test_data$wage)) * 100

MAPE_Wage_predicted_glm_1

```




```{r}
# Combine original test data with predicted values
combined_data_wage_predicted_glm_1 <- cbind(wage_test_data, Predicted_Wage = wage_predicted_glm_1)

# View the combined dataframe
head(combined_data_wage_predicted_glm_1)

tail(combined_data_wage_predicted_glm_1)
```





#### Aplicación de modelo MCG2

```{r}
# Predict wages using the test data
log_wage_predicted_glm_2_2<- predict(glm_2_2_wage_train_data, newdata = wage_test_data)

# Back-transform the predicted log wages to the original scale
wage_predicted_glm_2_2 <- exp(log_wage_predicted_glm_2_2)

# Calculate Mean Absolute Percentage Error (MAPE)
MAPE_wage_predicted_glm_2_2 <- mean(abs((wage_predicted_glm_2_2 - wage_test_data$wage) / wage_test_data$wage)) * 100

MAPE_wage_predicted_glm_2_2

```



```{r}
# Combine original test data with predicted values
combined_data_wage_predicted_glm_2_2 <- cbind(wage_test_data, Predicted_Wage = wage_predicted_glm_2_2)

# View the combined dataframe
head(combined_data_wage_predicted_glm_2_2)

tail(combined_data_wage_predicted_glm_2_2)
```






## Bibliografía 


https://ocw.mit.edu/courses/18-650-statistics-for-applications-fall-2016/2c0395a301a2ca798b1c0ee18cf6eedc_MIT18_650F16_Regression.pdf

https://ocw.mit.edu/courses/18-650-statistics-for-applications-fall-2016/dff89368051a5feae72b39c6422d0752_MIT18_650F16_GLM.pdf

https://web.vu.lt/mif/a.buteikis/wp-content/uploads/PE_Book/4-6-Multiple-GLS.html


