---
title: "Regresion_Class_19_Sept_2023_Modelos_Lineales"
author: "Sergibar"
date: "2023-08-29"
output: html_document
---

# Aplicación de modelos lineales 

## GPA

```{r}
library(readr)

df_gpa <- read_csv("gpa1RMEv1.csv")
df_gpa
```



### Aplicaición de modelo lineal a la data de colGPA como función de age o hsGPA, etc, etc


```{r}
# Load libraries
library(stats)

# Fit linear model 
lm_model_gpa1 <- lm(colGPA ~ age + hsGPA, data = df_gpa)

# View model summary
summary(lm_model_gpa1)
```

```{r}
names(df_gpa)
```

```{r}

# Load libraries
library(stats)

# Fit linear model 
lm_model_gpa2 <- lm(colGPA ~ . , data = df_gpa)

# View model summary
summary(lm_model_gpa2)

```




```{r}
# Load libraries
library(stats)

# Fit linear model 
lm_model_gpa2 <- lm(colGPA ~ age + male + campus + hsGPA + ACT + job19 + job20 + drive + bike + walk + PC + bgfriend + skipped + alcohol + fathcoll , data = df_gpa)

# View model summary
summary(lm_model_gpa2)
```

NOTAR COMO ESTÁ TOMANDO LA VARIABLE DICOTÓMICA WALK  y HACIENDO UNA ESPECIE DE SUSTITUCIÓN DE LA INTERCEPCIÓN 
Se formula la matriz de diseño con todas las variables + la columna de 1 del intercepto. Donde el número de renglones  (datos, registros), debe ser mayor al número de variables explicativas. (N-K no puede ser negativa)
La matriz de diseño debe ser de rango completo y en este caso si llegas caminando, no llegaste en bici ni en camion. Entonces en pricnipio no es de rango completo, y en principio  no tendría inversa. Pero R hace se trabajo de "escoger walk y quitarla"


PARA ELIMINAR LA VARIABLE DRIVE DEL MODELO LINEAL ORIGINAL

```{r}
# Fit linear model
lm_model_gpa2_dicotomica_sin_drive <- lm(colGPA ~ . - drive, data = df_gpa)

# View model summary
summary(lm_model_gpa2_dicotomica_sin_drive)
```


Tomando solo en cuenta las variables significativas 

```{r}
# Fit linear model
lm_model_gpa3 <- lm(colGPA ~ campus + hsGPA + PC + bgfriend + skipped , data = df_gpa)

# View model summary
summary(lm_model_gpa3)
```




Tomando solo en cuenta las variables significativas Y quitando bgfriend

```{r}
# Fit linear model
lm_model_gpa4 <- lm(colGPA ~ campus + hsGPA + PC + skipped , data = df_gpa)

# View model summary
summary(lm_model_gpa4)
```


Tomando solo en cuenta las variables significativas Y quitando bgfriend + campus 

```{r}
# Fit linear model
lm_model_gpa5 <- lm(colGPA ~  hsGPA + PC + skipped , data = df_gpa)

# View model summary
summary(lm_model_gpa5)
```

Vamos a hacer el histograma de la variable colGPA

```{r}
hist(df_gpa$colGPA)
```



Vamos a hacer el histograma de la variable colGPA

```{r}
min(df_gpa$colGPA)
```



Vamos a hacer el histograma de la variable hsGPA

```{r}
hist(df_gpa$hsGPA)
```



Vamos a hacer el histograma de la variable hsGPA

```{r}
hist(df_gpa$skipped)
```




### Graficación de la data de colGPA como función de algunas de sus variables explicativas, como por ejemplo age o hsGPA, etc, etc


```{r}
lm_model_gpa1$coefficients['age']*df_gpa$age
```


#### Grafica de GPA como función de edad

```{r}
plot(df_gpa$age, df_gpa$colGPA)
abline(lm_model_gpa1$coefficients['age']*df_gpa$age, col="blue")
```



#### Grafica de GPA como función de Skipped

```{r}
plot(df_gpa$skipped, df_gpa$colGPA)
```



#### Grafica de GPA como función de hsGPA

```{r}
plot(df_gpa$hsGPA, df_gpa$colGPA)
```



#### Grafica de GPA como función de PC

```{r}
plot(df_gpa$PC, df_gpa$colGPA)
```


