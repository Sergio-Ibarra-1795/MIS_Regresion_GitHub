---
title: "Examen_a_casa_aplicacion_de_GMLR_Ibarra_try0"
author: "SIR"
date: "2023-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### UNAM Posgrado en Ingeniería 
### Dr. Wulfrano Gomez Gallardo
### Alumno: Ibarra Ramírez Sergio 
<br>

### Ejemplo de aplicación de modelos Lineales Generalizados Multipes (GMLR Ó MCG) en el pronóstico de sueldos

<br>

#### El modelo General Lineal o Modelo Generalizado de Mínimos Cuadrados 
<br>

En general el modelo MCG asume los siguientes enunciados como ciertos:

 A. Las variables xi predictoras son linealmente indpendientes entre si, por lo que la matriz X es de rango completo
 B. Los errores siguen una distribución normal 
 C. El valor esperado del error dado los valores de la matriz X es cero 
 $$\mathbb{E} \left( \boldsymbol{\varepsilon} | \mathbf{X}\right) = \boldsymbol{0}$$
 D. La varianza del error dado los valores de la matriz X puede calcularse como: 
 
 $$\mathbb{V}{\rm ar}\left( \boldsymbol{\varepsilon} | \mathbf{X} \right)= \mathbb{E} \left( \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\top \right)$$
 es decir, 
 
$$ \mathbb{V}{\rm ar}\left( \boldsymbol{\varepsilon} | \mathbf{X} \right) = \mathbb{E} \left( \boldsymbol{\varepsilon} \boldsymbol{\varepsilon}^\top \right)= \boldsymbol{\Sigma} = \sigma_\epsilon^2 \mathbf{\Omega}$$


Donde ${\Omega}$ es una matriz cuadrada, simétrica y definida positiva de tamaño N × N. Este modelo permite que los errores sean heterocedásticos o autocorrelacionados (o ambos) y a menudo se denomina caso especial del modelo lineal generalizado (GLM).



Si ${\Omega}=I$, entonces el GMLR es simplemente el modelo de regresión lineal múltiple simple que discutimos al comienzo de este capítulo.


$$ {\Omega}= \begin{pmatrix}
1 & 0 & 0 & ..  0\\ 
0 &  1& 0 & ..  0\\
0 &  0& 1 & ..  0\\ 
0 & 0 & 0 &  ..  1 
\end{pmatrix}$$ 


Si ${\Omega}$ es diagonal con elementos diagonales no constantes, entonces los términos de error no están correlacionados pero son heterocedásticos.


$${\Omega}= \begin{pmatrix}
\omega_{1}  & 0 & 0 & ..  0\\ 
0 &  \omega_{2}& 0 & ..  0\\
0 &  0& \omega_{3} & ..  0\\ 
0 & 0 & 0 &  ..  \omega_{n} 
\end{pmatrix}$$


Si ${\Omega}$ no es diagonal, entonces $Cov(\varepsilon_{i}, \varepsilon_{j})={\Omega_{ij}\neq 0}$ En econometría, las matrices de covarianza no diagonales se encuentran con mayor frecuencia en los datos de series temporales, con correlaciones más altas para las observaciones más cercanas en el tiempo (generalmente cuando i y j difieren en 1 o 2).


Si ${\Omega}$ no es diagonal y los elementos diagonales son constantes, entonces los errores están autocorrelacionados y homocedásticos.

$${\Omega}= \begin{pmatrix}
\sigma^{2}  & \rho_{12} & \rho_{13} & ..\rho_{1N}\\ 
\rho_{21}  &  \sigma^{2}& \rho_{23}  & ..\rho_{2N} \\
\rho_{31}  &  \rho_{32} & \sigma^{2} & ..\rho_{3N} \\ 
\rho_{41}  &  \rho_{42}  & \rho_{43}  &  ..\sigma^{2} 
\end{pmatrix}$$



Si ${\Omega}$ no es diagonal y los elementos diagonales no son constantes, entonces los errores están autocorrelacionados y heterocedásticos.


$${\Omega}= \begin{pmatrix}
\omega_{1}  & \rho_{12} & \rho_{13} & ..\rho_{1N}\\ 
\rho_{21}  &  \omega_{2}& \rho_{23}  & ..\rho_{2N} \\
\rho_{31}  &  \rho_{32} & \omega_{3} & ..\rho_{3N} \\ 
\rho_{41}  &  \rho_{42}  & \rho_{43}  &  ..\omega_{N} 
\end{pmatrix}$$


<br>


#### El modelo General Lineal Simple o Modelo de Mínimos Cuadrados Ordinarios 

Consideremos al modelo de regresión lineal simple o modelo de Mínimos Cuadrados Ordinarios (OMS ó MCO) como: 

$$\begin{align}
\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}
\end{align}$$


##### Donde: <br>
Y: Vector de valores estimados <br>
X: Matriz ampliada de valores de las variables independientes xi <br>
$\beta$: Vector de estimadores de maxima verosimilitud calculado con el modelo MCO 


El cual asume: 

$$Y |X \sim \operatorname{N}(\mu(X), \sigma^2I)$$ 

##### Donde: <br>
Y: Vector de valores estimados <br>
X: Matriz ampliada de valores de las variables independientes xi <br>
$\mu(X)$ is the mean of the normal distribution, which is a function of X  <br>
$\sigma^2I$ is the variance of the normal distribution, where I is the identity matrix.

Y  por lo tanto: 

$$E(Y |X) = \mu(X) = \mathbf{X}^\top\boldsymbol{\beta}$$






https://ocw.mit.edu/courses/18-650-statistics-for-applications-fall-2016/dff89368051a5feae72b39c6422d0752_MIT18_650F16_GLM.pdf